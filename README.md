# FakeTextDetection

This study investigates detecting machinegenerated text from the human-generated text. This paper presents various approaches to building ML-based models, such as Logistic Regression(LR) and fine-tuning using the pre-trained model RoBERTa. We propose the BERT score as an evaluation metric along with perplexity and burstiness. We present sentiment as a semantic feature to make the model more robust and tune the dataset to make the model less prone to adversarial attacks. These findings can be an effective intervention in improving the existing models

Intro to wiki-dataset - https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro
